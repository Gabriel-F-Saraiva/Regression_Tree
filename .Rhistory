scale_color_viridis_d(direction = -1, begin=0, end=.25) +
theme(legend.position = "none") +
ggtitle(paste("Curva ROC Random Forest | AUC-treino=",
percent(tcs_treino[1], accuracy=0.1),
"| AUC_teste = ",
percent(tcs_teste[1], accuracy=0.1))
)
CurvaROC
avalia(gridsearch_rf)
#####
# Gerando os dados
# x é uma sequencia de valores entre 0 e 1
x <- seq(0,1, length.out=1000)
# y segue uma relação quadrática
a <- 0
b <- 10
c <- -10
set.seed(2360873)
y <- a + b*x + c*x**2 + rnorm(length(x), mean=0, sd=.1)
df <- data.frame(x, y)
p0 <- ggplot(df, aes(x,y)) +
geom_point(aes(colour='Observado')) +
scale_color_viridis(discrete=TRUE, begin=0, end=.85, name = "Valor") +
theme(legend.position="bottom",
legend.spacing.x = unit(0, 'cm'))
p0
########################
# Construindo a árvore #
tree <- rpart(y~x,
data=df,
control=rpart.control(maxdepth = 2, cp=0))
# Plotando a árvore
paleta = scales::viridis_pal(begin=.75, end=1)(20)
rpart.plot::rpart.plot(tree,
box.palette = paleta) # Paleta de cores
# Valores preditos
df['p'] = predict(tree, df)
df['r'] = df$y - df$p
# Valores esperados e observados
boost0_O_vs_E <- ggplot(df, aes(x,y)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,p, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
theme(legend.position="bottom") +
# guides(colour = guide_legend(label.position = "bottom")) +
labs(title="Valores observados vs esperados") +
scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
boost0_O_vs_E
# Gráfico de resíduos
boost0_res <- ggplot(df, aes(x,r)) +
geom_point(alpha=.7, size=.5, aes(colour='Resíduo')) +
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
theme(legend.position="bottom") +
labs(title="Gráfico de resíduos") +
scale_y_continuous(name= "r") +
scale_x_continuous(name= "x")
boost0_res
ggpubr::ggarrange(boost0_O_vs_E, boost0_res,
# labels = c("A", "B"),
ncol = 2, nrow = 1)
# Primeira iteração de boosting manual
tree1 <- rpart(r~x,
data=df,
control=rpart.control(maxdepth = 2, cp=0))
df['p1'] = predict(tree1, df)  # Predito da árvore neste passo
df['P1'] = df$p + df$p1        # Predito do boosting (acumulado)
df['r1'] = df$r - df$p1        # resíduo do boosting
# Gráfico da primeira iteração de boosting manual
# O QUE O MODELO ESTÁ FAZENDO
boost1_r_vs_E <- ggplot(df, aes(x,r)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,p1, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
labs(title="Variável resposta neste passo") +
theme_bw() +
theme(legend.position="bottom") +
scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
# O QUE ACONTECE COM O MODELO FINAL
boost1_O_vs_E <- ggplot(df, aes(x,y)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,P1, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
labs(title="Observado vs Esperado (final)") +
theme_bw() +
theme(legend.position="bottom") +
scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
# Gráfico de resíduos
boost1_r <- ggplot(df, aes(x,r1)) +
geom_point(alpha=.7, size=.5, aes(colour='Resíduo')) +
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
labs(title="Gráfico de resíduos (final)") +
theme_bw() +
theme(legend.position="bottom") +
scale_y_continuous(name= "r") +
scale_x_continuous(name= "x")
ggpubr::ggarrange(boost1_r_vs_E, boost1_O_vs_E, boost1_r,
# labels = c("A", "B"),
ncol = 3, nrow = 1)
tree2 <- rpart(r1~x,
data=df,
control=rpart.control(maxdepth = 2, cp=0))
df['p2'] = predict(tree2, df) # predito da árvore tree2
df['P2'] = df$P1 + df$p2      # predito do boosting neste passo
df['r2'] = df$r1 - df$p2      # resíduo da árvore neste passo (resíduo do boosting)
# Gráfico da primeira iteração de boosting manual
# O QUE O MODELO ESTÁ FAZENDO
boost2_r_vs_E <- ggplot(df, aes(x,r1)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,p2, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
labs(title="Variável resposta neste passo") +
theme_bw() +
theme(legend.position="bottom") +
scale_y_continuous(name= "y(i)") +
scale_x_continuous(name= "x")
# O QUE ACONTECE COM O MODELO FINAL
boost2_O_vs_E <- ggplot(df, aes(x,y)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,P2, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
labs(title="Observado vs Esperado (final)") +
theme_bw() +
theme(legend.position="bottom") +
scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
# Gráfico de resíduos
boost2_r <- ggplot(df, aes(x,r2)) +
geom_point(alpha=.7, size=.5, aes(colour='Resíduo')) +
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
labs(title="Gráfico de resíduos (final)") +
theme_bw() +
theme(legend.position="bottom") +
scale_y_continuous(name= "r") +
scale_x_continuous(name= "x")
boost2_O_vs_E
ggpubr::ggarrange(boost2_r_vs_E, boost2_O_vs_E, boost2_r,
# labels = c("A", "B"),
ncol = 3, nrow = 1)
set.seed(2360873)
# parâmetros do trainControl
#number: number of folds or resampling iterations
#repeats: for repeated k-fold cross-validation, the number of complete sets of folds to compute
tempo_ini <- Sys.time()
controle <- caret::trainControl(
"cv",
number = 10,
summaryFunction = twoClassSummary, # Função de avaliação de performance
classProbs = TRUE # Necessário para calcular a curva ROC
)
modelo <- caret::train(
Survived ~.,
data = treino,
method = "xgbTree",
trControl = controle,
tuneGrid = NULL,
verbosity = 0)
modelo
tempo_fim <- Sys.time()
tempo_fim - tempo_ini
avalia(modelo)
# Base de treino
avalia <- function(modelo, nome_modelo="modelo"){
p_treino <- predict(modelo, treino, type='prob') # Probabilidade predita
c_treino <- predict(modelo, treino)              # Classificação
#Base de teste
p_teste <- predict(modelo, teste, type='prob')
c_teste <- predict(modelo, teste)
# Data frame de avaliação (Treino)
aval_treino <- data.frame(obs=treino$Survived,
pred=c_treino,
Y = p_treino[,2],
N = 1-p_treino[,2]
)
# Data frame de avaliação (Teste)
aval_teste <- data.frame(obs=teste$Survived,
pred=c_teste,
Y = p_teste[,2],
N = 1-p_teste[,2]
)
tcs_treino <- caret::twoClassSummary(aval_treino,
lev=levels(aval_treino$obs))
tcs_teste <- caret::twoClassSummary(aval_teste,
lev=levels(aval_teste$obs))
##########################
# Curva ROC              #
CurvaROC <- ggplot2::ggplot(aval_teste, aes(d = obs, m = Y, colour='1')) +
plotROC::geom_roc(n.cuts = 0, color="blue") +
plotROC::geom_roc(data=aval_treino,
aes(d = obs, m = Y, colour='1'),
n.cuts = 0, color = "red") +
scale_color_viridis_d(direction = -1, begin=0, end=.25) +
theme(legend.position = "none") +
ggtitle(paste("Curva ROC | ", nome_modelo, " | AUC-treino=",
percent(tcs_treino[1]),
"| AUC_teste = ",
percent(tcs_teste[1]))
)
print('Avaliação base de treino')
print(tcs_treino)
print('Avaliação base de teste')
print(tcs_teste)
CurvaROC
}
avalia(treino_rf)
avalia(treino_rf, nome_modelo="Random Forest")
avalia(gridsearch_rf, nome_modelo='RF Tunado')
avalia(modelo, nome_modelo="XGBoosting")
load("/Volumes/GoogleDrive-105296192289087716243/Meu Drive/Pecege/OMML2/OMML2_proj/titanic.Rda")
########################
# Instalação de pacotes
load("titanic.Rda")
# Acurácia
acuracia_treino_rf <- confusionMatrix(rf_p_treino[,2], treino$Survived)$overall[['Accuracy']]
# Acurácia
acuracia_treino_rf <- confusionMatrix(rf_p_treino[,2], treino$Survived)$overall[['Accuracy']]
# Acurácia
rf_p_treino[,2]
# Acurácia
rf_p_treino[,2] %>% head
# Acurácia
rf_p_treino[,2] %>% dim
acuracia_treino_rf <- confusionMatrix(rf_p_treino[,2], treino$Survived)$overall[['Accuracy']]
acuracia_treino_rf <- confusionMatrix(rf_c_treino, treino$Survived)$overall[['Accuracy']]
# Acurácia
acuracia_treino_rf
?milticlass.roc
?milticlass.roc
update.packages(ask = FALSE, checkBuilt = TRUE)
library(tinytex)
tinytex::tlmgr_update()
options(tinytex.verbose = TRUE)
########################
# Instalação de pacotes
pacotes <- c(
'tidyverse',  # Pacote básico de datawrangling
'rpart',      # Biblioteca de árvores
'rpart.plot', # Conjunto com Rpart, plota a parvore
'gtools',     # funções auxiliares como quantcut,
'Rmisc',      # carrega a função sumarySE para a descritiva
'scales',     # importa paletas de cores
'viridis',    # Escalas 'viridis' para o ggplot2
'caret',       # Funções úteis para machine learning
'AMR',
'randomForest',
'fastDummies',
'rattle',
'xgboost'
)
if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
instalador <- pacotes[!pacotes %in% installed.packages()]
for(i in 1:length(instalador)) {
install.packages(instalador, dependencies = T)
break()}
sapply(pacotes, require, character = T)
} else {
sapply(pacotes, require, character = T)
}
#####
# Gerando os dados
# x é uma sequencia de valores entre 0 e 1
set.seed(2360873)
x <- seq(0,1, length.out=1000)
# y segue uma relação quadrática
a <- 0
b <- 10
c <- -10
y <- a + b*x + c*x**2 + rnorm(length(x), mean=0, sd=.1)
df <- data.frame(x, y)
p0 <- ggplot(df, aes(x,y)) +
geom_point(aes(colour='Observado')) +
scale_color_viridis(discrete=TRUE, begin=0, end=.85, name = "Valor") +
theme(legend.position="bottom",
legend.spacing.x = unit(0, 'cm'))
p0
########################
# Construindo a árvore #
tree <- rpart(y~x,
data=df,
control=rpart.control(maxdepth = 3, cp=0))
# Plotando a árvore
paleta = scales::viridis_pal(begin=.75, end=1)(20)
rpart.plot::rpart.plot(tree,
box.palette = paleta) # Paleta de cores
# Valores preditos
df['p'] = predict(tree, df)
df['r'] = df$y - df$p
# Valores esperados e observados
boost0_O_vs_E <- ggplot(df, aes(x,y)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,p, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
theme(legend.position="bottom") +
# guides(colour = guide_legend(label.position = "bottom")) +
labs(title="Valores observados vs esperados") +
scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
boost0_O_vs_E
# Gráfico de resíduos
boost0_res <- ggplot(df, aes(x,r)) +
geom_point(alpha=.7, size=.5, aes(colour='Resíduo')) +
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
theme(legend.position="bottom") +
labs(title="Gráfico de resíduos") +
scale_y_continuous(name= "r") +
scale_x_continuous(name= "x")
boost0_res
ggpubr::ggarrange(boost0_O_vs_E, boost0_res,
# labels = c("A", "B"),
ncol = 2, nrow = 1)
########################
# Instalação de pacotes
pacotes <- c(
'tidyverse',  # Pacote básico de datawrangling
'rpart',      # Biblioteca de árvores
'rpart.plot', # Conjunto com Rpart, plota a parvore
'gtools',     # funções auxiliares como quantcut,
'Rmisc',      # carrega a função sumarySE para a descritiva
'scales',     # importa paletas de cores
'viridis',    # Escalas 'viridis' para o ggplot2
'caret',       # Funções úteis para machine learning
'AMR',
'randomForest',
'fastDummies',
'rattle',
'xgboost'
)
if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
instalador <- pacotes[!pacotes %in% installed.packages()]
for(i in 1:length(instalador)) {
install.packages(instalador, dependencies = T)
break()}
sapply(pacotes, require, character = T)
} else {
sapply(pacotes, require, character = T)
}
set.seed(2360873)
x <- seq(0,1, length.out=1000)
# y segue uma relação quadrática
a <- 0
b <- 10
c <- -10
y <- a + b*x + c*x**2 + rnorm(length(x), mean=0, sd=.1)
df <- data.frame(x, y)
p0 <- ggplot(df, aes(x,y)) +
geom_point(aes(colour='Observado')) +
scale_color_viridis(discrete=TRUE, begin=0, end=.85, name = "Valor") +
theme(legend.position="bottom",
legend.spacing.x = unit(0, 'cm'))
p0
tree <- rpart(y~x,
data=df,
control=rpart.control(maxdepth = 3, cp=0))
paleta = scales::viridis_pal(begin=.75, end=1)(20)
rpart.plot::rpart.plot(tree,
box.palette = paleta) # Paleta de cores
View(boost1_r_vs_E)
# Buscar reprodutibilidade
set.seed(2360873)
# Gera 80% de 1´s e 20% de 2´s para separar as amostras
n <- sample(1:2, # vamos amostrar elementos do conjunto c(1,2)
size=nrow(titanic), # O tamanho da amostragem é 891
replace=TRUE, # Amostragem com reposição (de c(1,2))
prob=c(0.8,0.2)) # A probabilidade de ser 1 é 80%, de ser 2 é 20%
# Gera 80% de 1´s e 20% de 2´s para separar as amostras
n <- sample(1:2, # vamos amostrar elementos do conjunto c(1,2)
size=nrow(titanic), # O tamanho da amostragem é 891
replace=TRUE, # Amostragem com reposição (de c(1,2))
prob=c(0.8,0.2)) # A probabilidade de ser 1 é 80%, de ser 2 é 20%
########################
# Instalação de pacotes
pacotes <- c(
'tidyverse',  # Pacote básico de datawrangling
'rpart',      # Biblioteca de árvores
'rpart.plot', # Conjunto com Rpart, plota a parvore
'gtools',     # funções auxiliares como quantcut,
'Rmisc',      # carrega a função sumarySE para a descritiva
'scales',     # importa paletas de cores
'viridis',    # Escalas 'viridis' para o ggplot2
'caret',       # Funções úteis para machine learning
'AMR',
'randomForest',
'fastDummies',
'rattle',
'xgboost'
)
if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
instalador <- pacotes[!pacotes %in% installed.packages()]
for(i in 1:length(instalador)) {
install.packages(instalador, dependencies = T)
break()}
sapply(pacotes, require, character = T)
} else {
sapply(pacotes, require, character = T)
}
# Gera 80% de 1´s e 20% de 2´s para separar as amostras
n <- sample(1:2, # vamos amostrar elementos do conjunto c(1,2)
size=nrow(titanic), # O tamanho da amostragem é 891
replace=TRUE, # Amostragem com reposição (de c(1,2))
prob=c(0.8,0.2)) # A probabilidade de ser 1 é 80%, de ser 2 é 20%
########################
# Instalação de pacotes
pacotes <- c('titanic',    # carrega a base original titanic_treino
'tidyverse',  # Pacote básico de datawrangling
'rpart',      # Biblioteca de árvores
'rpart.plot', # Conjunto com Rpart, plota a parvore
'gtools',     # funções auxiliares como quantcut,
'Rmisc',      # carrega a função sumarySE para a descritiva
'scales',     # importa paletas de cores
'caret'       # Funções úteis para machine learning
)
if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
instalador <- pacotes[!pacotes %in% installed.packages()]
for(i in 1:length(instalador)) {
install.packages(instalador, dependencies = T)
break()}
sapply(pacotes, require, character = T)
} else {
sapply(pacotes, require, character = T)
}
# Gera 80% de 1´s e 20% de 2´s para separar as amostras
n <- sample(1:2, # vamos amostrar elementos do conjunto c(1,2)
size=nrow(titanic), # O tamanho da amostragem é 891
replace=TRUE, # Amostragem com reposição (de c(1,2))
prob=c(0.8,0.2)) # A probabilidade de ser 1 é 80%, de ser 2 é 20%
titanic %>% head
# Vamos criar uma base temporária para manter a base original intacta
tmp <- titanic
tmp$survived <- as.integer(titanic$Survived=="Y")
library(titanic)
# Buscar reprodutibilidade
set.seed(2360873)
# Gera 80% de 1´s e 20% de 2´s para separar as amostras
n <- sample(1:2, # vamos amostrar elementos do conjunto c(1,2)
size=nrow(titanic), # O tamanho da amostragem é 891
replace=TRUE, # Amostragem com reposição (de c(1,2))
prob=c(0.8,0.2)) # A probabilidade de ser 1 é 80%, de ser 2 é 20%
# Gera 80% de 1´s e 20% de 2´s para separar as amostras
n <- sample(1:2, # vamos amostrar elementos do conjunto c(1,2)
size=nrow(titanic), # O tamanho da amostragem é 891
replace=TRUE, # Amostragem com reposição (de c(1,2))
prob=c(0.8,0.2)) # A probabilidade de ser 1 é 80%, de ser 2 é 20%
library(titanic)
titanic <- library(titanic)
titanic
rm(titanic)
Titanic
titanic %>% head
Titanic %>% head
# Gera 80% de 1´s e 20% de 2´s para separar as amostras
n <- sample(1:2, # vamos amostrar elementos do conjunto c(1,2)
size=nrow(Titanic), # O tamanho da amostragem é 891
replace=TRUE, # Amostragem com reposição (de c(1,2))
prob=c(0.8,0.2)) # A probabilidade de ser 1 é 80%, de ser 2 é 20%
# Amostra de treino: n==1 (os 80%)
treino <- titanic[n==1,]
titanic::
titanic::titanic_gender_model
titanic <- titanic_test
titanic <- titanic_train
# Buscar reprodutibilidade
set.seed(2360873)
# Gera 80% de 1´s e 20% de 2´s para separar as amostras
n <- sample(1:2, # vamos amostrar elementos do conjunto c(1,2)
size=nrow(titanic), # O tamanho da amostragem é 891
replace=TRUE, # Amostragem com reposição (de c(1,2))
prob=c(0.8,0.2)) # A probabilidade de ser 1 é 80%, de ser 2 é 20%
# Amostra de treino: n==1 (os 80%)
treino <- titanic[n==1,]
# Amostra de teste: n==2 (os 20%)
teste <- titanic[n==2,]
View(treino)
View(treino)
View(boost0_res)
View(boost0_res)
titanic <- titanic_train
titanic::titanic_gender_model
titanic <- titanic_train
library(titanic)
titanic <- titanic_train
########################
# Instalação de pacotes
pacotes <- c(
'tidyverse',  # Pacote básico de datawrangling
'rpart',      # Biblioteca de árvores
'rpart.plot', # Conjunto com Rpart, plota a parvore
'gtools',     # funções auxiliares como quantcut,
'Rmisc',      # carrega a função sumarySE para a descritiva
'scales',     # importa paletas de cores
'viridis',    # Escalas 'viridis' para o ggplot2
'caret',       # Funções úteis para machine learning
'AMR',
'randomForest',
'fastDummies',
'rattle',
'xgboost'
)
if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
instalador <- pacotes[!pacotes %in% installed.packages()]
for(i in 1:length(instalador)) {
install.packages(instalador, dependencies = T)
break()}
sapply(pacotes, require, character = T)
} else {
sapply(pacotes, require, character = T)
}
